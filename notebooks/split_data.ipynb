{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fix Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modetype = 'diri' # 'iid', 'diri', 'clsimb'\n",
    "\n",
    "clsimb = [2, 7] # [2, 7], [2, 3, 4], [3, 3, 3] for 'clsimb'\n",
    "\n",
    "splits = 9 * 2 # for 'iid' and 'diri'\n",
    "if modetype == 'clsimb':\n",
    "    splits = sum(clsimb)\n",
    "alpha = 0.01 # 0.01, 1.5 for 'diri'\n",
    "\n",
    "if modetype == 'clsimb':\n",
    "    mode = '{}{}c{}'.format(modetype, sum(clsimb), ''.join(str(x) for x in clsimb))\n",
    "elif modetype == 'diri':\n",
    "    mode = '{}{}a{}'.format(modetype, splits, ''.join(e for e in str(alpha) if e.isalnum()))\n",
    "elif modetype == 'iid':\n",
    "    mode = f'{modetype}{splits}'\n",
    "    if modetype == 'diri':\n",
    "        mode = f'{modetype}{splits // 2}'\n",
    "    \n",
    "dataset = 'cifar10'\n",
    "\n",
    "filename = f'{dataset}_{mode}_{seed}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "os.makedirs(path_data, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "classes = np.arange(10)\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    train_dataset = datasets.CIFAR10(path_data, train=True, download=True)\n",
    "    train_size = 714 * 2\n",
    "elif dataset == 'svhn':\n",
    "    train_dataset = datasets.SVHN(path_data, split='train', download=True)\n",
    "    train_size = 1065 * 2\n",
    "    if clsimb == [2, 7]:\n",
    "        classes = [1, 2, 3, 4]\n",
    "elif dataset == 'fmnist':\n",
    "    train_dataset = datasets.FashionMNIST(path_data, train=True, download=True)\n",
    "    train_size = 857 * 2\n",
    "elif dataset == 'mnist':\n",
    "    train_dataset = datasets.MNIST(path_data, train=True, download=True)\n",
    "    train_size = 851 * 2\n",
    "    if clsimb == [2, 7]:\n",
    "        classes = [1, 2, 3, 7]\n",
    "elif dataset == 'stl10':\n",
    "    train_dataset = datasets.STL10(path_data, split='train', download=True)\n",
    "    train_size = 71 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    y = train_dataset.targets\n",
    "except AttributeError:\n",
    "    y = train_dataset.labels\n",
    "if type(y) is torch.Tensor:\n",
    "    y = y.tolist()\n",
    "    \n",
    "# c = np.asarray(list(Counter(y).items()))\n",
    "# c = c[c[:,1].argsort()[::-1][:len(c)]]\n",
    "# j = c[:,1]\n",
    "# t = j // 7\n",
    "\n",
    "# for x in t:\n",
    "#     print(x, len(j[j >= x * 4]), j[j >= x * 4], len(j[j >= x * 7]), j[j >= x * 7])\n",
    "\n",
    "labels = np.asarray(y)\n",
    "num_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clsplit(clsimb, classes, desig=2):\n",
    "    outputs = []\n",
    "    \n",
    "    for _ in clsimb:\n",
    "        c = np.random.choice(classes, desig, replace=False)\n",
    "        c.sort()\n",
    "        c = c.tolist()\n",
    "        outputs.append(c)\n",
    "        classes = [x for x in classes if x not in c]\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 8], [2, 5]]\n"
     ]
    }
   ],
   "source": [
    "classes = clsplit(clsimb, classes, 2)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichlet_split(dataset, splits, alpha=0.05, min_size=0, min_required_size=10, K=10, train_size=1/3, seed=42):\n",
    "    try:\n",
    "        labels = np.asarray(dataset.targets)\n",
    "    except AttributeError:\n",
    "        labels = np.asarray(dataset.labels)\n",
    "\n",
    "    idx_batch = [[] for _ in range(splits)]\n",
    "    clients = {}\n",
    "    \n",
    "    if train_size > 0:\n",
    "        labels, _ = train_test_split(labels, train_size=train_size, random_state=seed, shuffle=True, stratify=labels)\n",
    "    \n",
    "    while min_size < min_required_size:\n",
    "        idx_batch = [[] for _ in range(splits)]\n",
    "\n",
    "        for k in range(K):\n",
    "            idx_k = np.where(labels == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "            proportions = np.random.dirichlet(np.repeat(alpha, splits))\n",
    "            proportions = np.array([p * (len(idx_j) < len(dataset) / splits) for p, idx_j in zip(proportions, idx_batch)])\n",
    "            proportions = proportions / proportions.sum()\n",
    "            proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "            idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "            \n",
    "    for j in range(splits):\n",
    "        np.random.shuffle(idx_batch[j])\n",
    "        clients[j] = {'index': idx_batch[j], 'label': labels[idx_batch[j]].tolist()}\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(dataset, splits, train_size, indices, seed=42):\n",
    "\n",
    "    try:\n",
    "        labels = np.asarray(dataset.targets)[indices]\n",
    "    except AttributeError:\n",
    "        labels = np.asarray(dataset.labels)[indices]\n",
    "    clients = {}\n",
    "    \n",
    "    for i in range(splits):\n",
    "        split_x, indices, split_y, labels = train_test_split(indices, labels, train_size=train_size, random_state=seed, shuffle=True, stratify=labels)\n",
    "        clients[i] = {'index': split_x.tolist(), 'label': split_y.tolist()}\n",
    "\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makesubset(dataset, target_cls):\n",
    "    try:\n",
    "        truths = dataset.targets\n",
    "    except AttributeError:\n",
    "        truths = dataset.labels\n",
    "    boolarr = [True if y in target_cls else False for y in truths]\n",
    "    indices = np.arange(len(dataset))\n",
    "    subset_idx = indices[boolarr]\n",
    "    return subset_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_imbalanced_split(dataset, splits, classes, train_size, seed=42):\n",
    "    groups = [makesubset(dataset, c) for c in classes]\n",
    "\n",
    "    clients = {}\n",
    "    t, i = 0, 0\n",
    "    for g in groups:\n",
    "        client_group = stratified_split(dataset, max(splits), train_size, g, seed=seed)\n",
    "        for k, v in client_group.items():\n",
    "            if k < splits[i]:\n",
    "                clients[t] = v\n",
    "            else:\n",
    "                i += 1\n",
    "                break\n",
    "            t += 1\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dist(clients):\n",
    "    cnt = 0\n",
    "    for k, v in clients.items():\n",
    "        classes = []\n",
    "        for c in range(10):\n",
    "            if c in np.unique(v['label']):\n",
    "                classes.append(c)\n",
    "            else:\n",
    "                classes.append('_')\n",
    "        print(f\"[{k:>2}]  #sample  {len(v['index']):>5d}  >>  Classes  {' '.join(str(y) for y in classes)}  ({len(np.unique(v['label'])):>2d})  >>  {sorted(Counter(v['label']).items())}\")\n",
    "        cnt += len(v['index'])\n",
    "\n",
    "    print(f'---\\n[Total] {cnt}')\n",
    "    print(f'\\n#sample_left {len(train_dataset)} - {cnt} = {len(train_dataset) - cnt}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0]  #sample   1220  >>  Classes  _ 1 _ _ _ _ 6 _ _ _  ( 2)  >>  [(1, 17), (6, 1203)]\n",
      "[ 1]  #sample    884  >>  Classes  _ _ _ 3 _ _ _ _ _ _  ( 1)  >>  [(3, 884)]\n",
      "[ 2]  #sample   2755  >>  Classes  _ _ _ _ _ 5 _ _ 8 9  ( 3)  >>  [(5, 1303), (8, 1327), (9, 125)]\n",
      "[ 3]  #sample    862  >>  Classes  _ 1 _ _ _ _ 6 7 _ _  ( 3)  >>  [(1, 32), (6, 296), (7, 534)]\n",
      "[ 4]  #sample    169  >>  Classes  _ _ _ _ 4 _ _ _ _ _  ( 1)  >>  [(4, 169)]\n",
      "[ 5]  #sample   1596  >>  Classes  0 _ _ _ 4 _ _ _ _ _  ( 2)  >>  [(0, 1498), (4, 98)]\n",
      "[ 6]  #sample    911  >>  Classes  _ _ _ _ _ _ _ 7 _ _  ( 1)  >>  [(7, 911)]\n",
      "[ 7]  #sample   1084  >>  Classes  _ _ _ _ _ _ _ _ 8 9  ( 2)  >>  [(8, 172), (9, 912)]\n",
      "[ 8]  #sample   1447  >>  Classes  _ 1 _ _ _ _ _ _ _ _  ( 1)  >>  [(1, 1447)]\n",
      "[ 9]  #sample     53  >>  Classes  _ _ _ _ _ _ _ 7 _ _  ( 1)  >>  [(7, 53)]\n",
      "[10]  #sample    462  >>  Classes  _ _ _ _ _ _ _ _ _ 9  ( 1)  >>  [(9, 462)]\n",
      "[11]  #sample   1221  >>  Classes  _ 1 _ _ 4 _ _ _ _ _  ( 2)  >>  [(1, 1), (4, 1220)]\n",
      "[12]  #sample     79  >>  Classes  _ _ _ _ _ 5 _ 7 _ _  ( 2)  >>  [(5, 78), (7, 1)]\n",
      "[13]  #sample     13  >>  Classes  _ _ _ _ 4 _ _ _ _ _  ( 1)  >>  [(4, 13)]\n",
      "[14]  #sample     21  >>  Classes  _ _ _ _ _ 5 _ _ _ _  ( 1)  >>  [(5, 21)]\n",
      "[15]  #sample   1499  >>  Classes  _ _ 2 _ _ _ _ _ _ _  ( 1)  >>  [(2, 1499)]\n",
      "[16]  #sample    102  >>  Classes  0 1 2 _ _ 5 _ _ _ _  ( 4)  >>  [(0, 1), (1, 2), (2, 1), (5, 98)]\n",
      "[17]  #sample    622  >>  Classes  0 1 _ 3 _ _ 6 7 8 9  ( 7)  >>  [(0, 1), (1, 1), (3, 616), (6, 1), (7, 1), (8, 1), (9, 1)]\n",
      "---\n",
      "[Total] 15000\n",
      "\n",
      "#sample_left 50000 - 15000 = 35000\n",
      "\n",
      ">>>>> Drop classes with <= 20 sample!\n",
      "\n",
      "[ 0]  #sample   1203  >>  Classes  _ _ _ _ _ _ 6 _ _ _  ( 1)  >>  [(6, 1203)]\n",
      "[ 1]  #sample    884  >>  Classes  _ _ _ 3 _ _ _ _ _ _  ( 1)  >>  [(3, 884)]\n",
      "[ 2]  #sample   2755  >>  Classes  _ _ _ _ _ 5 _ _ 8 9  ( 3)  >>  [(5, 1303), (8, 1327), (9, 125)]\n",
      "[ 3]  #sample    862  >>  Classes  _ 1 _ _ _ _ 6 7 _ _  ( 3)  >>  [(1, 32), (6, 296), (7, 534)]\n",
      "[ 4]  #sample    169  >>  Classes  _ _ _ _ 4 _ _ _ _ _  ( 1)  >>  [(4, 169)]\n",
      "[ 5]  #sample   1596  >>  Classes  0 _ _ _ 4 _ _ _ _ _  ( 2)  >>  [(0, 1498), (4, 98)]\n",
      "[ 6]  #sample    911  >>  Classes  _ _ _ _ _ _ _ 7 _ _  ( 1)  >>  [(7, 911)]\n",
      "[ 7]  #sample   1084  >>  Classes  _ _ _ _ _ _ _ _ 8 9  ( 2)  >>  [(8, 172), (9, 912)]\n",
      "[ 8]  #sample   1447  >>  Classes  _ 1 _ _ _ _ _ _ _ _  ( 1)  >>  [(1, 1447)]\n",
      "[ 9]  #sample     53  >>  Classes  _ _ _ _ _ _ _ 7 _ _  ( 1)  >>  [(7, 53)]\n",
      "[10]  #sample    462  >>  Classes  _ _ _ _ _ _ _ _ _ 9  ( 1)  >>  [(9, 462)]\n",
      "[11]  #sample   1220  >>  Classes  _ _ _ _ 4 _ _ _ _ _  ( 1)  >>  [(4, 1220)]\n",
      "[12]  #sample     78  >>  Classes  _ _ _ _ _ 5 _ _ _ _  ( 1)  >>  [(5, 78)]\n",
      "[13]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[14]  #sample     21  >>  Classes  _ _ _ _ _ 5 _ _ _ _  ( 1)  >>  [(5, 21)]\n",
      "[15]  #sample   1499  >>  Classes  _ _ 2 _ _ _ _ _ _ _  ( 1)  >>  [(2, 1499)]\n",
      "[16]  #sample     98  >>  Classes  _ _ _ _ _ 5 _ _ _ _  ( 1)  >>  [(5, 98)]\n",
      "[17]  #sample    616  >>  Classes  _ _ _ 3 _ _ _ _ _ _  ( 1)  >>  [(3, 616)]\n",
      "---\n",
      "[Total] 14958\n",
      "\n",
      "#sample_left 50000 - 14958 = 35042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if modetype == 'clsimb':\n",
    "    clients = class_imbalanced_split(dataset=train_dataset, splits=clsimb, classes=classes, train_size=train_size, seed=seed)\n",
    "elif modetype == 'diri':\n",
    "    clients = dirichlet_split(dataset=train_dataset, splits=splits, alpha=alpha, min_size=0, min_required_size=10, K=num_classes, train_size=0.3, seed=seed)\n",
    "elif modetype == 'iid':\n",
    "    clients = stratified_split(dataset=train_dataset, splits=splits, train_size=train_size, indices=indices, seed=seed)\n",
    "\n",
    "display_dist(clients)\n",
    "\n",
    "thres = 20\n",
    "print(f'>>>>> Drop classes with <= {thres} sample!\\n')\n",
    "\n",
    "inter = dict.fromkeys(clients.keys())\n",
    "\n",
    "for k, v in clients.items():\n",
    "    inter[k] = {}\n",
    "    arr = np.asarray(list(Counter(v['label']).items()))\n",
    "    arr = arr[arr[:,1] > thres]\n",
    "    boolarr = np.isin(np.asarray(v['label']), arr[:,0])\n",
    "    inter[k]['index'] = list(np.asarray(v['index'])[boolarr])\n",
    "    inter[k]['label'] = list(np.asarray(v['label'])[boolarr])\n",
    "    \n",
    "display_dist(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix(inter, fromclient, target, toclient):\n",
    "    indices = np.asarray(inter[fromclient]['index'])\n",
    "    labels = np.asarray(inter[fromclient]['label'])\n",
    "    boolarr = np.isin(labels, target)\n",
    "    inter[toclient]['index'].extend(list(indices[boolarr]))\n",
    "    inter[toclient]['label'].extend(list(labels[boolarr]))\n",
    "    inter[fromclient]['index'] = list(indices[~boolarr])\n",
    "    inter[fromclient]['label'] = list(labels[~boolarr])\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0]  #sample   1819  >>  Classes  _ _ _ 3 _ _ 6 _ _ _  ( 2)  >>  [(3, 616), (6, 1203)]\n",
      "[ 1]  #sample   1081  >>  Classes  _ _ _ 3 _ 5 _ _ _ _  ( 2)  >>  [(3, 884), (5, 197)]\n",
      "[ 2]  #sample   2630  >>  Classes  _ _ _ _ _ 5 _ _ 8 _  ( 2)  >>  [(5, 1303), (8, 1327)]\n",
      "[ 3]  #sample    915  >>  Classes  _ 1 _ _ _ _ 6 7 _ _  ( 3)  >>  [(1, 32), (6, 296), (7, 587)]\n",
      "[ 4]  #sample   1668  >>  Classes  _ _ 2 _ 4 _ _ _ _ _  ( 2)  >>  [(2, 1499), (4, 169)]\n",
      "[ 5]  #sample   1596  >>  Classes  0 _ _ _ 4 _ _ _ _ _  ( 2)  >>  [(0, 1498), (4, 98)]\n",
      "[ 6]  #sample   2131  >>  Classes  _ _ _ _ 4 _ _ 7 _ _  ( 2)  >>  [(4, 1220), (7, 911)]\n",
      "[ 7]  #sample   1084  >>  Classes  _ _ _ _ _ _ _ _ 8 9  ( 2)  >>  [(8, 172), (9, 912)]\n",
      "[ 8]  #sample   2034  >>  Classes  _ 1 _ _ _ _ _ _ _ 9  ( 2)  >>  [(1, 1447), (9, 587)]\n",
      "[ 9]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[10]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[11]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[12]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[13]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[14]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[15]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[16]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "[17]  #sample      0  >>  Classes  _ _ _ _ _ _ _ _ _ _  ( 0)  >>  []\n",
      "---\n",
      "[Total] 14958\n",
      "\n",
      "#sample_left 50000 - 14958 = 35042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = mix(inter, 17, 3, 0)\n",
    "tmp = mix(tmp, 16, 5, 1)\n",
    "tmp = mix(tmp, 15, 2, 4)\n",
    "tmp = mix(tmp, 14, 5, 1)\n",
    "\n",
    "tmp = mix(tmp, 12, 5, 1)\n",
    "tmp = mix(tmp, 11, 4, 6)\n",
    "tmp = mix(tmp, 10, 9, 2)\n",
    "tmp = mix(tmp, 9, 9, 6)\n",
    "\n",
    "tmp = mix(tmp, 2, 9, 8)\n",
    "tmp = mix(tmp, 9, 7, 3)\n",
    "\n",
    "display_dist(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(inter):\n",
    "    for k in list(inter.keys()):\n",
    "        if len(inter[k]['label']) == 0:\n",
    "            inter.pop(k)\n",
    "        else:\n",
    "            inter[k]['index'] = [int(x) for x in inter[k]['index']]\n",
    "            inter[k]['label'] = [int(x) for x in inter[k]['label']]\n",
    "    clients = dict.fromkeys([str(x) for x in inter.keys()])\n",
    "    for i, (k, v) in enumerate(inter.items()):\n",
    "        clients[str(i)] = v\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0]  #sample   1819  >>  Classes  _ _ _ 3 _ _ 6 _ _ _  ( 2)  >>  [(3, 616), (6, 1203)]\n",
      "[ 1]  #sample   1081  >>  Classes  _ _ _ 3 _ 5 _ _ _ _  ( 2)  >>  [(3, 884), (5, 197)]\n",
      "[ 2]  #sample   2630  >>  Classes  _ _ _ _ _ 5 _ _ 8 _  ( 2)  >>  [(5, 1303), (8, 1327)]\n",
      "[ 3]  #sample    915  >>  Classes  _ 1 _ _ _ _ 6 7 _ _  ( 3)  >>  [(1, 32), (6, 296), (7, 587)]\n",
      "[ 4]  #sample   1668  >>  Classes  _ _ 2 _ 4 _ _ _ _ _  ( 2)  >>  [(2, 1499), (4, 169)]\n",
      "[ 5]  #sample   1596  >>  Classes  0 _ _ _ 4 _ _ _ _ _  ( 2)  >>  [(0, 1498), (4, 98)]\n",
      "[ 6]  #sample   2131  >>  Classes  _ _ _ _ 4 _ _ 7 _ _  ( 2)  >>  [(4, 1220), (7, 911)]\n",
      "[ 7]  #sample   1084  >>  Classes  _ _ _ _ _ _ _ _ 8 9  ( 2)  >>  [(8, 172), (9, 912)]\n",
      "[ 8]  #sample   2034  >>  Classes  _ 1 _ _ _ _ _ _ _ 9  ( 2)  >>  [(1, 1447), (9, 587)]\n",
      "---\n",
      "[Total] 14958\n",
      "\n",
      "#sample_left 50000 - 14958 = 35042\n",
      "\n",
      "[ 0]  #sample   1819  >>  Classes  _ _ _ 3 _ _ 6 _ _ _  ( 2)  >>  [(3, 616), (6, 1203)]\n",
      "[ 1]  #sample   1081  >>  Classes  _ _ _ 3 _ 5 _ _ _ _  ( 2)  >>  [(3, 884), (5, 197)]\n",
      "[ 2]  #sample   2630  >>  Classes  _ _ _ _ _ 5 _ _ 8 _  ( 2)  >>  [(5, 1303), (8, 1327)]\n",
      "[ 3]  #sample    915  >>  Classes  _ 1 _ _ _ _ 6 7 _ _  ( 3)  >>  [(1, 32), (6, 296), (7, 587)]\n",
      "[ 4]  #sample   1668  >>  Classes  _ _ 2 _ 4 _ _ _ _ _  ( 2)  >>  [(2, 1499), (4, 169)]\n",
      "[ 5]  #sample   1596  >>  Classes  0 _ _ _ 4 _ _ _ _ _  ( 2)  >>  [(0, 1498), (4, 98)]\n",
      "[ 6]  #sample   2131  >>  Classes  _ _ _ _ 4 _ _ 7 _ _  ( 2)  >>  [(4, 1220), (7, 911)]\n",
      "[ 7]  #sample   1084  >>  Classes  _ _ _ _ _ _ _ _ 8 9  ( 2)  >>  [(8, 172), (9, 912)]\n",
      "[ 8]  #sample   2034  >>  Classes  _ 1 _ _ _ _ _ _ _ 9  ( 2)  >>  [(1, 1447), (9, 587)]\n",
      "---\n",
      "[Total] 14958\n",
      "\n",
      "#sample_left 50000 - 14958 = 35042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = cleanup(tmp)\n",
    "display_dist(tmp)\n",
    "\n",
    "clients = cleanup(tmp)\n",
    "display_dist(clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_data, filename + '.json'), 'w') as f:\n",
    "    json.dump(clients, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
